# Framework de Testing para ElevenLabs Agents ğŸ§ª

Framework automatizado de testing para agentes conversacionales de ElevenLabs con soporte para dos flujos: **simulaciÃ³n directa** y **tests persistentes**.

## ğŸ¯ CaracterÃ­sticas

- âœ… **DefiniciÃ³n de tests en YAML**: Formato simple y legible
- ğŸ”„ **Dos flujos de testing**:
  - **SimulaciÃ³n directa**: Ejecuta tests inmediatamente sin guardarlos
  - **Tests persistentes**: Guarda tests en ElevenLabs para reutilizar
- ğŸ“Š **Reportes detallados**: JSON y Markdown con mÃ©tricas completas
- ğŸ¨ **CLI amigable**: Interface con colores y spinners
- ğŸ“ **Criterios personalizables**: Define tus propios criterios de evaluaciÃ³n

## ğŸ“‹ Requisitos

- Node.js 18+
- Cuenta de ElevenLabs con API key
- Agent ID de tu agente

## ğŸš€ InstalaciÃ³n

```bash
cd testingElevenLabs
npm install
```

Configura el `.env`:

```env
ELEVENLABS_API_KEY=tu_api_key
ELEVENLABS_AGENT_ID=tu_agent_id
```

## ğŸ“– Comandos Disponibles

### 1. SimulaciÃ³n Directa (`simulate`)

Ejecuta tests inmediatamente usando la API de simulaciÃ³n:

```bash
npm run simulate
```

âœ¨ **CuÃ¡ndo usar**: Desarrollo rÃ¡pido, iteraciÃ³n de prompts, testing ad-hoc

### 2. Crear Tests Persistentes (`create`)

Guarda tests en tu cuenta de ElevenLabs:

```bash
npm run create
```

Retorna IDs de tests creados que puedes reutilizar.

### 3. Ejecutar Tests Persistentes (`run`)

Ejecuta tests ya creados en ElevenLabs:

```bash
npm run run -- --agent agent_123 --tests test_456 test_789
```

âœ¨ **CuÃ¡ndo usar**: CI/CD, testing programado, tests de regresiÃ³n

### 4. Listar Tests (`list`)

Lista todos los tests de un agente:

```bash
npm run list -- --agent agent_123
```

### 5. Generar Reporte (`report`)

Genera reporte Markdown desde resultados:

```bash
npm run report results/test-results-*.json
```

## ğŸ“ Crear Tests

### Dos Enfoques de Testing

#### ğŸ”„ SimulaciÃ³n Directa (`npm run simulate`)
Ejecuta conversaciones completas multi-turno. El usuario simulado (LLM) interactÃºa con tu agente por varios turnos, luego se evalÃºa toda la conversaciÃ³n.

**CuÃ¡ndo usar**: Desarrollo, iteraciÃ³n de prompts, testing de flujos conversacionales completos

#### ğŸ’¾ Tests Persistentes (`npm run create` + `npm run run`)
Crea tests de un solo turno guardados en ElevenLabs. El agente responde UNA vez y se compara contra ejemplos.

**CuÃ¡ndo usar**: CI/CD, testing automatizado, validaciÃ³n de regresiÃ³n

âš ï¸ **IMPORTANTE**: NO mezcles ambos enfoques en el mismo test.

### Formato YAML

```yaml
name: "Nombre del Test"
description: "QuÃ© valida este test"
agent_id: "${ELEVENLABS_AGENT_ID}"
type: "llm"  # Solo para tests persistentes

simulated_user:
  # IMPORTANTE: prompt debe ser un STRING simple
  prompt: "Comportamiento del usuario simulado..."
  first_message: "Hola"
  language: "es"
  temperature: 0.4  # Opcional: 0.0-1.0

# OPCIÃ“N 1: Para simulaciÃ³n directa (conversaciÃ³n completa)
evaluation_criteria:
  - id: "criterion-1"
    name: "Criterio de Ã‰xito"
    prompt: "EvalÃºa si el agente cumpliÃ³ con..."
    use_knowledge_base: false

# OPCIÃ“N 2: Para tests persistentes (un solo turno)
success_condition: "El agente debe..."
success_examples:
  - "Respuesta apropiada ejemplo 1"
failure_examples:
  - "Respuesta inapropiada ejemplo 1"

dynamic_variables:
  nombre_cliente: "MarÃ­a GonzÃ¡lez"
  documento: "1234567"
```

**ğŸ“– Ver plantilla completa**: `tests/template.yaml`

### 3 Tests de Ejemplo Incluidos

- `happy-path.yaml`: Flujo exitoso completo
- `invalid-data.yaml`: Manejo de datos invÃ¡lidos
- `callback-scheduling.yaml`: Agendamiento de callbacks

## ğŸ”„ Flujos de Trabajo

### Desarrollo RÃ¡pido

```bash
# 1. Crea tu test YAML en tests/scenarios/
# 2. Ejecuta simulaciÃ³n
npm run simulate

# 3. Revisa resultados en results/
# 4. Itera ajustando el YAML
```

### ProducciÃ³n/CI

```bash
# 1. Crea tests persistentes una vez
npm run create

# 2. Guarda los test IDs
# 3. Ejecuta en CI/CD
npm run run -- --agent $AGENT_ID --tests $TEST_IDS

# 4. Verifica resultados
```

## ğŸ“Š Resultados

### Console Output

```
âœ… ValidaciÃ³n Exitosa - Happy Path (6/6 criterios, 12500ms)
âŒ Manejo de Datos InvÃ¡lidos (4/5 criterios, 15200ms)
```

### JSON (`results/test-results-*.json`)

```json
{
  "generated_at": "2025-01-11T...",
  "total_tests": 3,
  "successful_tests": 2,
  "results": [...]
}
```

### Markdown (`results/report-*.md`)

Reporte completo con:
- Resumen ejecutivo
- Tabla de tests
- Transcripciones completas
- Criterios y rationales

## ğŸ—ï¸ Estructura del Proyecto

```
testingElevenLabs/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/elevenlabs-client.ts      # Cliente API
â”‚   â”œâ”€â”€ testing/
â”‚   â”‚   â”œâ”€â”€ test-runner.ts            # Ejecutor
â”‚   â”‚   â””â”€â”€ reporter.ts               # Reportes
â”‚   â”œâ”€â”€ types/index.ts                # Tipos TS
â”‚   â””â”€â”€ index.ts                      # CLI
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ template.yaml                 # Plantilla
â”‚   â””â”€â”€ scenarios/                    # Tests
â””â”€â”€ results/                          # Resultados
```

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Variables DinÃ¡micas

Personaliza tests sin duplicar:

```yaml
dynamic_variables:
  nombre_cliente: "Juan"
  monto: "1000000"
```

### Tool Mocking

Simula herramientas externas:

```yaml
tool_mock_config:
  consultar_db:
    return_value: "OK"
    should_fail: false
```

## ğŸ› Troubleshooting

### Error: ELEVENLABS_API_KEY no encontrada

```bash
cat .env | grep ELEVENLABS_API_KEY
```

### Error 422 al crear tests

Verifica que `agent_id` sea correcto y el agente exista.

### Tests lentos

Reduce `new_turns_limit`:

```yaml
new_turns_limit: 20
```

## ğŸ”— Enlaces

- [DocumentaciÃ³n ElevenLabs](https://elevenlabs.io/docs)
- [API Reference - Tests](https://elevenlabs.io/docs/api-reference/tests/create)
- [API Reference - Simulate](https://elevenlabs.io/docs/api-reference/agents/simulate-conversation)

---

**Desarrollado para testing automatizado de agentes de ElevenLabs** ğŸš€
